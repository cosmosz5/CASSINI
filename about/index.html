<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>CS for SAM - CASSINI</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">CASSINI</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Home</a>
                            </li>
                            <li class="navitem">
                                <a href="../SAMpip/" class="nav-link">SAMPip</a>
                            </li>
                            <li class="navitem">
                                <a href="../NN/" class="nav-link">NN for imaging</a>
                            </li>
                            <li class="navitem">
                                <a href="../RCAR/" class="nav-link">GRAVITY - RCAR analysis</a>
                            </li>
                            <li class="navitem active">
                                <a href="./" class="nav-link">CS for SAM</a>
                            </li>
                            <li class="navitem">
                                <a href="../cs_pca/" class="nav-link">CS PCA</a>
                            </li>
                            <li class="navitem">
                                <a href="../Publications/" class="nav-link">Publications</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../RCAR/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../cs_pca/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="2"><a href="#this-repository-includes-software-to-recover-infrared-interferometric-images-based-on-compressed-sensing-cassini-lasso" class="nav-link">This repository includes software to recover infrared interferometric images based on Compressed Sensing (CASSINI-LASSO)</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#link-to-the-github-repository-with-the-code-click-here" class="nav-link">Link to the GitHub repository with the code, click HERE</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#1-brief-introduction-to-compressed-sensing" class="nav-link">1. Brief Introduction to Compressed Sensing</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#2-james-webb-space-telescope-simulations" class="nav-link">2. James-Webb Space Telescope Simulations</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#3-image-reconstruction-based-on-compressed-sening" class="nav-link">3. Image reconstruction based on Compressed Sening</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#summary" class="nav-link">SUMMARY</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h2 id="this-repository-includes-software-to-recover-infrared-interferometric-images-based-on-compressed-sensing-cassini-lasso">This repository includes software to recover infrared interferometric images based on Compressed Sensing (CASSINI-LASSO)</h2>
<h2 id="link-to-the-github-repository-with-the-code-click-here">Link to the GitHub repository with the code, click <a href="https://github.com/cosmosz5/CASSINI">HERE</a></h2>
<h1 id="1-brief-introduction-to-compressed-sensing">1. Brief Introduction to Compressed Sensing</h1>
<p align="justify">
Compressed Sensing (CS) allows us to recover a signal with less samples that the ones established from the Nyquist/Shannon theorem. For the technique to work, the signal must be sparse and compressible on a given basis. It means that the signal can be represented by a linear combination of functions with a small number of non-zero coefficients. In CS, a set of measurements, <strong>y</strong>, of a given signal, <strong>x</strong>, can be encoded by a multiplication of the matrices <strong>&Phi;</strong>, <strong>&Psi;</strong>, and the sparse vector <strong>&alpha;</strong>. <strong>&Psi;</strong> is the transformation basis where the full signal, <strong>x</strong>, is sparse, and only a few coefficients in the vector <strong>&alpha;</strong> are non-zero. <strong>&Phi;</strong> is, thus, the system of measurements under which the data are taken. For a visual representation of the matrices involved in CS see Fig. 1. It is important to remark that the number of measurements in <strong>y</strong> is considerably smaller than the number of features/columns in  in <strong>&Psi;</strong>, therefore, the inverse problem to find <strong>&alpha;</strong> is "ill-posed". CS establishes that if the product &Theta; = <strong>&Phi;&Psi;</strong> satisfies the Restricted Isometry Property (RIP), we will be able to recover the signal from the sub-sampled measurements. Therefore, compressed Sensing offers us a framework to solve the "ill-posed" inverse problem by a regularized optimization, using as prior the sparsity of &alpha; and/or the degree of compressibility of the signal. 
</p>

<p align="justify">
This repository includes code to recover infrared interferometric images using CS from simulated Aperture Masking data. The Aperture Masking data is simulated as expected to be recorded by the near-infrared imager NIRISS on-board of the James Webb Space Telescope (JWST).

</p>

<figure>
<p><img alt="Dummy image" height="400" src="../Images/CS_1_v2.png" width="800" />
  </p>
<figcaption> <strong>Figure 1. </strong> Schematic Representation of the Compressed Sensing algorithm </figcaption>
</figure>
<h1 id="2-james-webb-space-telescope-simulations">2. James-Webb Space Telescope Simulations</h1>
<p>NIRISS (Near Infrared Imager and Slitless Spectrograph) is an infrared (band-pass = 0.8 - 5μm) high-resolution camera which allows us to observe an object using Fizeau interferometry in the form of Sparse Aperture Masking (SAM).
We obtained the simualted data from our collaboration with the NIRISS team at the Space Telescope Science Institute (STScI). In order to reduce the interferograms of the simulatiosn, we fitted the fringes directly in the image plane using a model of the mask geometry and filter bandwidth, using our software <a href="../SAMpip/">CASSINI-SAMPip</a>.</p>
<p>The SAM data included as example to run the code consisted in the simulation of an inclined and asymmetric proto-planetary disk observed at three different filters (see Table 1) with the following central wavelengths:  3.8μm, 4.3μm and 4.8μm.  Given the pointing limitations of the JWST, we considered a maximum of three pointing positions at a position angle(E-&gt;N) of -10<sup>◦</sup>, 0<sup>◦</sup> and 10<sup>◦</sup>. To make the JWST/SAM simulations as realistic as possible, we included piston errors between 10 and 50 nm.  These are typical expected error values of the instrumental transfer function.  The simulated science data were calibrated with simulated interferograms of point-like objects with similar pistonerrors as the science data.  The u-v coverage employed for image reconstruction includes 318 data points (V<sup>2</sup> + Fourier phases + CPs) and combines the different simulated pointing positions and wavelengths (see Fig. 2).</p>
<figure>
<p><img alt="Dummy image2" height="400" src="../Images/jwst11.png" width="800" />
  </p>
<figcaption> <strong>Figure 2.</strong> <strong>right:</strong> u-v coverage of our JWST-SAM simulations. <strong>left:</strong> Simulated inteferogram of a proto-planetary disk as observed with the SAM mode of the JWST. </figcaption>
</figure>
<figure>
<p><img alt="Dummy image2" height="200" src="../Images/niriss_filters.png" width="600" />
  </p>
<figcaption><strong>Table 1.</strong> Simulated NIRISS filters. </figcaption>
</figure>
<h2 id="3-image-reconstruction-based-on-compressed-sening">3. Image reconstruction based on Compressed Sening</h2>
<p>The code for the reconstruction is included in the sub-directory <strong>LASSO</strong> of the main <strong>CASSINI</strong> repository. To solve the image optimization problem, the python <code>scikit-learn</code> library was used. More explicitly, the Least Absolute Shrinkage and Selection Operator (LASSO) algorithm was selected. This LASSO implementation uses a regularized minimization of the following form:</p>
<figure>
<p><img alt="Dummy image2" height="70" src="../Images/lasso_eq.png" width="800" /></p>
</figure>
<p>where N is the total number of elements in the sampled signal, y, and λ is the value of the hyperparameter that weights the regularizer. It is important to remark that the constraint region of the l1-norm has the form of an hypercube with several corners, which ensure sparsity of &alpha; for a convex optimization problem.  This is not the case by using, for example a Ridge regression with ‖&alpha;‖<sup>2</sup><sub>2</sub>, where the constraint region is a rotational invariant n-sphere.  This can also be interpreted as LASSO being a linear regression model with a Laplace prior distribution, with a sharp peak at its mean. In contrast, Gaussian prior distribution of coefficients in a Ridge regression has a more soften peak around its mean.</p>
<figure>
<p><img alt="Dummy image2" height="600" src="../Images/diagram_lasso2.png" width="800" />
  </p>
<figcaption> <strong>Figure 3.</strong> The diagram shows a visual representation of the CS LASSO implementation of our work. A Dictionary of models (<strong>&theta;</strong> = <strong>&Phi;&Psi;</strong>) is created with a group of images (<strong>&Psi;</strong>), which are transformed into the measured observables atthe simulated u-v plane (<strong>&Phi;</strong>). Then, the Dictionary is compared with the data (<strong>y</strong>) and a set of non-zero coefficients (<strong>&alpha;</strong>) are selected. This process is repeated over a given number of iterations until the best-fit reconstructed image (<strong>x</strong>) is obtained. </figcaption>
</figure>
<p>Before performing the minimization, a precomputed Dictionary (Θ) with 10<sup>4</sup> different disk-like structures was created. The random images of the disks were created  using a pixel grid of 71×71 pixels with a pixelscale of 10 milliarcseconds (mas). To transform those images into the system of measurements of our data, their Fourier transform were performed using a proprietary implementation of the regularly spaced Fast Fourier Transform (FFT) and, the observables (squared visibilities, Fourier phases and closure phases) were obtained for the sampled u-v frequencies. Together with the code in this repository, we included a sample of the dictionary build from our database of models. The code <code>create_dict.py</code> is an example of how can we read a set of images and transform them into the Fourier Space sampled with our data. This script imports the script called <code>oitools.py</code>.</p>
<p><code>oitools.py</code> contains a small library of routines to perform transformations and data extraction on both, the visibility domain and the image one. One of the most interesting and, indeed, the one that is used to extract the interferometric observables from the images is <mark>oitools.compute_vis_matrix</mark>. This piece of code uses a dedicated Direct Fourier Transform to get specific amplitudes and phases from the images at the specific spatial frequencies sampled with an interferometric array. The code is the following one: </p>
<pre><code class="language-py">
def compute_vis_matrix(im, u, v, scale):
    import numpy as np
    import math
    import pdb
    sz = np.shape(im)
    if sz[0] % 2 == 0:
        x, y = np.mgrid[-np.floor(sz[1] / 2 - 1):np.floor(sz[1] / 2):sz[1] * 1j,
               np.floor(sz[0] / 2 - 1):-np.floor(sz[0] / 2):sz[0] * 1j]
    else:
        x, y = np.mgrid[-np.floor(sz[1] / 2):np.floor(sz[1] / 2):sz[1] * 1j,
               np.floor(sz[0] / 2):-np.floor(sz[0] / 2):sz[0] * 1j]
    x = x * scale
    y = y * scale
    xx = x.reshape(-1)
    yy = y.reshape(-1)
    im = im.reshape(-1)
    arg = -2.0 * math.pi * (u * yy + v * xx)
    reales = im.dot(np.cos(arg))
    imaginarios = im.dot(np.sin(arg))
    visib = np.linalg.norm([reales, imaginarios])
    phase_temp = np.arctan2(imaginarios, reales)
    phase = np.rad2deg((phase_temp + np.pi) % (2 * np.pi) - np.pi)
    return visib, phase

</code></pre>
<p>The input parameters in <mark>oitools.compute_vis_matrix</mark> are: (i) the image from which the observables are computed; (ii) the u and v coordinates of the interferometer and; (iii) the pixel scale used in the image (this input is in units of radians). </p>
<p><code>create_dict.py</code> also centered and scaled each set of observables to have a mean equals to zero and standard deviation equals to the unity. Finally, the different observables were merged into a single column vector (or atom). The different atoms were stacked to create the different columns of the final Dictionary and stored into a Python binary file. Once the Dictionary was integrated, the assembled dictionary of protoplanetary disks is included in the repository enconded into a numpy binary file. <mark>(filename = Dict3.npy)</mark>.</p>
<p>Once the Dictionary was integrated, LASSO was used to solve for the non-zero coefficients of α that fit the observables and reconstruct the image.  LASSO worked over 10<sup>3</sup> iterations with a pre-defined value of the hyperparameter λ. Figure 4 displays a schematic representation of the described algorithm.</p>
<p align="justify"> 
This is the main part of the code for recovering the images from the interferometric data. The code to run LASSO is called `CS_JWST_v1.py`. This routines uses the dictionary (in this case Dict3.npy) together with the combined data set to recover an image. The user has to modify the following entry parameters in the script: 
</p>

<pre><code class="language-py">
oi_data = 'COMB_JWST_SAM_tot.fits'  #This is the filename of the input (COMBINED) data set
dict_filename = 'Dict3.npy' #Dictionary filename
input_path = ['dataset/']  # Input path for the galery of model images
scale = 10.0 # Pixel scale of the generated images in milliarcseconds
hyperparameter = 0.5 # Hyperparameter lambda for the LASSO minimization
maxit = 10000 # Maximum number of iterations for the reconstruction
output_filename = 'recovered_im_lasso.fits' #Output filename

</code></pre>
<p><strong>IMPORTANT:</strong> In case you want to run LASSO on your local machine, you need the DATABASE of models in the <mark>dataset/</mark> directory. The repository includes a copy of this DATABASE but it is partially truncated because of space in the GitHub repository. Before running the code, please download the complete DATABASE from this <a href="https://www.dropbox.com/sh/mtadpwbpns6nsvf/AABYHEQiMpuWPGvMvLqVLACVa?dl=0">Dropbox link</a> and put it inside the <mark>LASSO</mark> directory before running the code. </p>
<p>The script <code>CS_JWST_v1.py</code> returns the recovered image in .fits format. Figure 4 shows the best-fit image obtained with our CS LASSO algorithm together with the original model image. For the example showed in this simulation, the general structure of the disk is reproduced. The reconstructed morphology shows the correct inclination and position angle. It also shows the brighter emission of the ring along the semi-major axis. The inner cavity is also clearly observed. However, the size of the semi-minor axis is larger than the one of the model image. This can be appreciated in the map of the residuals formed by subtracting the image model from the reconstructed one. Figure 5 shows that the observables are well reproduced by the reconstructed image.</p>
<figure>
<p><img alt="Dummy image2" height="200" src="../Images/mod_lasso_ress.png" width="800" />
  </p>
<figcaption> <strong>Figure 4. </strong> <strong>Left:</strong> Model image from which the simulated data were obtained. <strong>Middle:</strong> Reconstructed CS LASSO image. <strong>Right:</strong> Map of residuals. The <strong>left</strong> and <strong>right</strong> panels are normalized to the unity and the color map scale is the same for an easy comparison between the two of them. </figcaption>
</figure>
<figure>
<p><img alt="Dummy image2" height="350" src="../Images/observables_001_2.png" width="800" />
  </p>
<figcaption> <strong>Figure 5. </strong>  Comparison between the data (black dots) and the recovered Squared visibilities and Closure Phases from the reconstructed CS LASSO images. The <strong>left</strong> panel displays the squared visibilities versus spatial frequency while the <strong>right</strong> panel shows the closure phases versus spatial frequencies. </figcaption>
</figure>
<p>To verify the quality of the reconstructions with the original set of observables, the repository includes the script called <code>plot_obs.py</code>. This piece of code produces a PNG file called "observables.png". This plot is similar to Figure 5 and it shows a comparison between the extracted obsevables from the reconstructed image and the original data. The input parameters of <code>plot_obs.py</code> are:</p>
<pre><code class="language-py">
oi_data = 'COMB_JWST_SAM_tot.fits' #Data filename
im_rec = np.squeeze(pyfits.getdata('reconvered_im_lasso_0.001.fits')) #Recovered image filename
wave_range = [3.0e-6, 5.0e-6] #Wavelength range of the observations
scale = 10.0 ## Pixel scale in milliarcseconds
</code></pre>
<p>To  evaluate the quality of our reconstructions, we also generated images using two other codes available in  the  community: BSMEM and SQUEEZE. The first one uses maximum entropy for the regularization and a gradient descent method with a trust region for the minimization. The second one could use different types of regularizations, including sparsity (in the form of the l0-norm). For the minimization a Markov-Chain Monte-Carlo (MCMC) algorithm  is  employed.  Similar pixel scale and grid parameters between CS and the reconstructions using BSMEM and SQUEEZE were used. Fig. 6 shows the  reconstructions obtained with each one of the different software. Notice that the three algorithms managed to recover the general (position angle and size) structure of the target. However, different artifacts are observed. For example, the BSMEM image shows the two brightest spots of the disk. However, it does not recover the central cavity. This can be easily explained because the Maximum Entropy enforces a smooth brightness transition between the different pixels in the image. The SQUEEZE reconstruction using the l0-norm shows a map with a ”granular” structure, which does not provide well defined loci for the maximum. This image does not show a clear cavity. We remark that the SQUEEZE image can be improved by using additional regularizers. Nevertheless, this is obtained at the cost of being slower. Also, the selection of the hyperaparameters becomes more complicated for more regularizers involved in the reconstruction. Both the SQUEEZE and BSMEM images show additional artifacts around the central source. This is not the case of the CS LASSO image, which shows a uniform background. To estimate the signal-to-noise ratio (SNR) between the peak of the emission and the noise floor of the images, we computed the mean value of the background using all the pixels outside a circular mask with a radius of 15 pixels centered at the middle of the image. The SNR values are: 3.7 x 10<sup>4</sup>, 1.0 x 10<sup>2</sup> and 0.8 x 10<sup>2</sup> for the CS LASSO, SQUEEZE and BSMEM images, respectively.  These values suggest that the CS LASSO reconstruction achieved a contrast two orders of magnitude larger than the other reconstructions.  This is particularly encouraging for the case of high-contrast observations as the ones expected with the JWST. </p>
<figure>
<p><img alt="Dummy image2" height="200" src="../Images/lasso_bsm_sq.png" width="800" />
  </p>
<figcaption> <strong>Figure 7.</strong> <strong>Left:</strong> Reconstructed CS LASSO image. <strong>Middle:</strong> Reconstructed SQUEEZE image. <strong>Right:</strong> Reconstructed BSMEM image.  </figcaption>
</figure>
<h1 id="summary">SUMMARY</h1>
<ul>
<li>
<p><code>To extract observables from SAM data</code> - Run <a href="../SAMpip/">CASSINI-SAMPip</a> Modify the script <code>test.py</code> or create a new one according with the data to be reduced. A description of the parameters used for the setup is included in this webpage. </p>
</li>
<li>
<p><code>To combine SAM data</code> - Run the <code>oi_combine.py</code> script inside the SAMpip directory. Modify the script according with the data to be combined. An oifits file is produced. A description of the parameters used for the setup is included in this webpage.</p>
</li>
<li>
<p><code>To create a dictionary of structures for imaging</code> - From a given galery of images with the desired structures, use the script  <code>create_dict.py</code>. This code converts the images into atoms of the dictionary in the Fourier Space. For this, it uses the transformation routines included in <code>oitools.py</code>. The user can run <code>create_dict.py</code> at the root directory of the repository. This step should create a .npy binary file with the dictionary of structures to be used for the reconstruction. </p>
</li>
<li>
<p><code>To recover an image</code> - With the dictionary, run <code>CS_JWST_v1.py</code>. An example of the input parameters is included in this webpage. This code will produce the reconstructed image. To evaluate the quality of the reconstruction, the user can con <code>plot_obs.py</code>, in order to produce a plot of the synthetic observables extracted from the best-reconstructed image and the dataset. </p>
</li>
<li>
<p><code>Additional tools</code> - We recommed the user to explore <code>oitools.py</code>. This script contains a series of transformations and data handling routines that could be useful for evaluating the quality of the reconstructions and/or to vizualize the data. </p>
</li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Author - Joel Sanchez Bermudez (Instituto de Astronomia de la Universidad Nacional Autonoma de Mexico). This code has been developed with funding from the UNAM PAPIIT project IA 101220 and from the Mexico's National Council of Humanities, Science and Technology (CONAHyCyT) “Ciencia de Frontera” project 263975</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/jquery-3.6.0.min.js"></script>
        <script src="../js/bootstrap.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="../javascripts/mathjax.js"></script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
